{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project:\n",
    "# Whatsapp Chat sentiment analyzer\n",
    "\n",
    "# Author : Pranshu Sharma\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing various dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-1.2.0-py3-none-any.whl (131 kB)\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.8.1-cp38-cp38-win_amd64.whl (155 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\pranshu sharma\\anaconda3\\lib\\site-packages (from wordcloud) (1.18.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\pranshu sharma\\anaconda3\\lib\\site-packages (from wordcloud) (3.2.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\pranshu sharma\\anaconda3\\lib\\site-packages (from wordcloud) (7.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\pranshu sharma\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\pranshu sharma\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\pranshu sharma\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pranshu sharma\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pranshu sharma\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib->wordcloud) (1.15.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\pranshu sharma\\anaconda3\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: click in c:\\users\\pranshu sharma\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\pranshu sharma\\anaconda3\\lib\\site-packages (from nltk) (0.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pranshu sharma\\anaconda3\\lib\\site-packages (from nltk) (4.61.0)\n",
      "Requirement already satisfied: regex in c:\\users\\pranshu sharma\\anaconda3\\lib\\site-packages (from nltk) (2020.6.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\pranshu sharma\\anaconda3\\lib\\site-packages (from vaderSentiment) (2.24.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\pranshu sharma\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\pranshu sharma\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pranshu sharma\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\pranshu sharma\\anaconda3\\lib\\site-packages (from requests->vaderSentiment) (1.25.9)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\PRANSHU\n",
      "[nltk_data]     SHARMA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emoji\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Designing Functions for extraction of information liketime etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Time\n",
    "def date_time(s):\n",
    "    pattern = '^([0-9]+)(\\/)([0-9]+)(\\/)([0-9]+), ([0-9]+):([0-9]+)[ ]?(AM|PM|am|pm)? -'\n",
    "    result = re.match(pattern, s)\n",
    "    if result:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Find Authors or Contacts\n",
    "def find_author(s):\n",
    "    s = s.split(\":\")\n",
    "    if len(s)==2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Finding Messages\n",
    "def getDatapoint(line):\n",
    "    splitline = line.split(' - ')\n",
    "    dateTime = splitline[0]\n",
    "    date, time = dateTime.split(\", \")\n",
    "    message = \" \".join(splitline[1:])\n",
    "    if find_author(message):\n",
    "        splitmessage = message.split(\": \")\n",
    "        author = splitmessage[0]\n",
    "        message = \" \".join(splitmessage[1:])\n",
    "    else:\n",
    "        author= None\n",
    "    return date, time, author, message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the txt file of Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "conversation = 'WhatsApp Chat with debashish.txt'\n",
    "\n",
    "with open(conversation, encoding=\"utf-8\") as fp:\n",
    "    fp.readline()\n",
    "    messageBuffer = []\n",
    "    date, time, author = None, None, None\n",
    "    while True:\n",
    "        line = fp.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        line = line.strip()\n",
    "        if date_time(line):\n",
    "            if len(messageBuffer) > 0:\n",
    "                data.append([date, time, author, ' '.join(messageBuffer)])\n",
    "            messageBuffer.clear()\n",
    "            date, time, author, message = getDatapoint(line)\n",
    "            messageBuffer.append(message)\n",
    "        else:\n",
    "            messageBuffer.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Text, ( Natural Language Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date      Time               Author            Message  Positive  \\\n",
      "0 2020-11-12  10:12 pm            debashish    <Media omitted>     0.000   \n",
      "1 2020-11-12  10:15 pm  Pranshu à¨—à¨¬à¨°à©‚ à¤¶à¤°à¥à¤®à¤¾ğŸ’«  thanks a lot bhai     0.592   \n",
      "2 2020-11-12  10:15 pm            debashish              ğŸš¾ Bro     0.000   \n",
      "3 2020-11-12  10:15 pm  Pranshu à¨—à¨¬à¨°à©‚ à¤¶à¤°à¥à¤®à¤¾ğŸ’«                 ğŸ˜ŠğŸ˜Š     0.000   \n",
      "4 2020-11-12  10:16 pm            debashish                  ğŸ‘     0.000   \n",
      "\n",
      "   Negative  Neutral  \n",
      "0       0.0    1.000  \n",
      "1       0.0    0.408  \n",
      "2       0.0    1.000  \n",
      "3       0.0    1.000  \n",
      "4       0.0    0.000  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=[\"Date\", 'Time', 'Author', 'Message'])\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "data = df.dropna()\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sentiments = SentimentIntensityAnalyzer()\n",
    "data[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data[\"Message\"]]\n",
    "data[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data[\"Message\"]]\n",
    "data[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in data[\"Message\"]]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral ğŸ™‚ \n"
     ]
    }
   ],
   "source": [
    "x = sum(data[\"Positive\"])\n",
    "y = sum(data[\"Negative\"])\n",
    "z = sum(data[\"Neutral\"])\n",
    "\n",
    "def sentiment_score(a, b, c):\n",
    "    if (a>b) and (a>c):\n",
    "        print(\"Positive ğŸ˜Š \")\n",
    "    elif (b>a) and (b>c):\n",
    "        print(\"Negative ğŸ˜  \")\n",
    "    else:\n",
    "        print(\"Neutral ğŸ™‚ \")\n",
    "sentiment_score(x, y, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Therefore we can analyze texts on whatsapp as mentioned above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing a function to take whatsapp chat .txt file as an input in a systematic way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_chat(a):\n",
    "    data = []\n",
    "    conversation = a\n",
    "\n",
    "    with open(conversation, encoding=\"utf-8\") as fp:\n",
    "        fp.readline()\n",
    "        messageBuffer = []\n",
    "        date, time, author = None, None, None\n",
    "        while True:\n",
    "          line = fp.readline()\n",
    "          if not line:\n",
    "            break\n",
    "          line = line.strip()\n",
    "          if date_time(line):\n",
    "            if len(messageBuffer) > 0:\n",
    "                data.append([date, time, author, ' '.join(messageBuffer)])\n",
    "            messageBuffer.clear()\n",
    "            date, time, author, message = getDatapoint(line)\n",
    "            messageBuffer.append(message)\n",
    "        else:\n",
    "            messageBuffer.append(line)\n",
    "            \n",
    "    df = pd.DataFrame(data, columns=[\"Date\", 'Time', 'Author', 'Message'])\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    data = df.dropna()\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "    sentiments = SentimentIntensityAnalyzer()\n",
    "    data[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in data[\"Message\"]]\n",
    "    data[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in data[\"Message\"]]\n",
    "    data[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in data[\"Message\"]]\n",
    "    print(data.head())       \n",
    "    x = sum(data[\"Positive\"])\n",
    "    y = sum(data[\"Negative\"])\n",
    "    z = sum(data[\"Neutral\"])\n",
    "    \n",
    "    print()\n",
    "    print(\"The Sentiment Analyzer:\")\n",
    "\n",
    "    def sentiment_score(a, b, c):\n",
    "      if (a>b) and (a>c):\n",
    "        print(\"Positive ğŸ˜Š \")\n",
    "      elif (b>a) and (b>c):\n",
    "        print(\"Negative ğŸ˜  \")\n",
    "      else:\n",
    "        print(\"Neutral ğŸ™‚ \")\n",
    "    sentiment_score(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a ='WhatsApp Chat with debashish.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date      Time               Author            Message  Positive  \\\n",
      "0 2020-11-12  10:12 pm            debashish    <Media omitted>     0.000   \n",
      "1 2020-11-12  10:15 pm  Pranshu à¨—à¨¬à¨°à©‚ à¤¶à¤°à¥à¤®à¤¾ğŸ’«  thanks a lot bhai     0.592   \n",
      "2 2020-11-12  10:15 pm            debashish              ğŸš¾ Bro     0.000   \n",
      "3 2020-11-12  10:15 pm  Pranshu à¨—à¨¬à¨°à©‚ à¤¶à¤°à¥à¤®à¤¾ğŸ’«                 ğŸ˜ŠğŸ˜Š     0.000   \n",
      "4 2020-11-12  10:16 pm            debashish                  ğŸ‘     0.000   \n",
      "\n",
      "   Negative  Neutral  \n",
      "0       0.0    1.000  \n",
      "1       0.0    0.408  \n",
      "2       0.0    1.000  \n",
      "3       0.0    1.000  \n",
      "4       0.0    0.000  \n",
      "\n",
      "The Sentiment Analyzer:\n",
      "Neutral ğŸ™‚ \n"
     ]
    }
   ],
   "source": [
    "predict_chat(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date     Time               Author  \\\n",
      "0 2018-11-24  4:55 pm  Pranshu à¨—à¨¬à¨°à©‚ à¤¶à¤°à¥à¤®à¤¾ğŸ’«   \n",
      "1 2018-11-24  4:55 pm  Pranshu à¨—à¨¬à¨°à©‚ à¤¶à¤°à¥à¤®à¤¾ğŸ’«   \n",
      "2 2018-11-24  4:55 pm  Pranshu à¨—à¨¬à¨°à©‚ à¤¶à¤°à¥à¤®à¤¾ğŸ’«   \n",
      "3 2018-11-24  5:14 pm  Pranshu à¨—à¨¬à¨°à©‚ à¤¶à¤°à¥à¤®à¤¾ğŸ’«   \n",
      "4 2018-11-24  5:14 pm  Pranshu à¨—à¨¬à¨°à©‚ à¤¶à¤°à¥à¤®à¤¾ğŸ’«   \n",
      "\n",
      "                                             Message  Positive  Negative  \\\n",
      "0                                        Hi aunty ğŸ˜ƒğŸ™‚     0.000     0.000   \n",
      "1                                  It's pranshu here     0.000     0.000   \n",
      "2                                                  ğŸ™‚     0.000     0.000   \n",
      "3  I wanted to have a sort of conversation with u...     0.081     0.000   \n",
      "4                              Sorry for bothering u     0.000     0.796   \n",
      "\n",
      "   Neutral  \n",
      "0    1.000  \n",
      "1    1.000  \n",
      "2    0.000  \n",
      "3    0.919  \n",
      "4    0.204  \n",
      "\n",
      "The Sentiment Analyzer:\n",
      "Neutral ğŸ™‚ \n"
     ]
    }
   ],
   "source": [
    "b = 'WhatsApp Chat with Aunty.txt'\n",
    "predict_chat(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
